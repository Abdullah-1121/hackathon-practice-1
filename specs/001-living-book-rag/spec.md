# Feature Specification: The Living Book Project: Cybernetic Documentation with AI

**Feature Branch**: `001-living-book-rag`
**Created**: 2025-11-26
**Status**: Draft
**Input**: User description: "Specification: The Living Book Project
1. Product Overview
We are building a "Cybernetic Book"â€”a Next-Gen documentation site that combines static content with active intelligence.

The Content: A Docusaurus 3.0 site titled "[INSERT TITLE HERE]".

The Intelligence: An embedded AI Agent (OpenAI ChatKit) that "reads" the book along with the user and answers questions using a RAG (Retrieval-Augmented Generation) backend.

2. Feature Set: The Frontend (Docusaurus 3.0)
Core Framework: Use the classic Docusaurus preset with a custom color scheme (e.g., #2e8555 for Python theme).

Navigation Structure:

Sidebar: Autogenerated from the file structure in /docs.

Navbar: Links to "Chapters", "About", and "GitHub Repo".

Swizzled Architecture:

You MUST swizzle the Root component (src/theme/Root.js) to wrap the entire application.

Why: This allows the Chat Widget to persist (stay open/active) even when the user navigates between chapters.

3. Feature Set: The Killer Feature (Selection Search)
User Story: "As a reader, I want to highlight a confusing paragraph and ask the AI to explain just that specific text."

Technical Implementation:

Event Listener: The Root component must listen for the global mouseup event.

Detection: If window.getSelection().toString() is not empty, render a Floating Action Button (FAB) near the mouse cursor.

Action: Clicking the FAB must:

Open the ChatKit widget.

Inject a system message or context object containing the selected text.

Pre-fill the user input with: "Explain this context: ..."

4. Feature Set: The Backend (FastAPI + RAG)
API Framework: FastAPI running on localhost:8000.

Database: Qdrant Cloud (Free Tier).

Endpoints:

POST /api/chat: Main RAG endpoint.

POST /api/index: Admin endpoint to trigger book indexing.

RAG Logic (The "Brain"):

Receive: User Query + (Optional) Selected Text.

Embed: Convert query to vector using Google Gemini (text-embedding-004).

Search: Query Qdrant for the top 3 relevant book chunks.

Synthesize: Send (Query + Selected Text + Retrieved Chunks) to the LLM for the final answer.

5. Data Pipeline: The Librarian Script
Script Location: scripts/index_book.py

Responsibility:

Scan all .md files in the /docs folder.

Chunking: Split text by headers (##) or paragraphs (approx 500 tokens).

Embedding: Call Google Gemini API (with time.sleep(1) to respect rate limits).

Upsert: Upload vectors + metadata (Chapter Title, Page URL) to Qdrant.

6. Deployment Strategy
Platform: GitHub Pages.

Workflow:

Create .github/workflows/deploy.yml.

Action: On push to main, build Docusaurus (npm run build) and deploy to gh-pages branch."

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Read with AI Context (Priority: P1)

As a reader, I want to highlight a confusing paragraph and ask the AI to explain just that specific text.

**Why this priority**: This is the "killer feature" that differentiates the "Cybernetic Book" and provides immediate value to the user by enhancing comprehension.

**Independent Test**: A user can navigate to any chapter, highlight text, click the FAB, and receive an AI explanation of the selected context, pre-filling the chat input.

**Acceptance Scenarios**:

1. **Given** a user is reading a chapter, **When** they highlight a section of text, **Then** a Floating Action Button (FAB) appears near the cursor.
2. **Given** a FAB is displayed after text selection, **When** the user clicks the FAB, **Then** the ChatKit widget opens, the selected text is injected as context, and the input field is pre-filled with "Explain this context: ...".
3. **Given** the ChatKit widget is open with pre-filled text, **When** the user submits the query, **Then** the RAG backend processes the request and returns an explanation based on the selected text and book content.

---

### User Story 2 - General Book Chat (Priority: P2)

As a reader, I want to ask general questions about the book's content at any time.

**Why this priority**: Provides a continuous interactive experience and leverages the RAG backend for broader information retrieval.

**Independent Test**: A user can open the ChatKit widget and ask a question about any topic covered in the book, receiving a relevant answer.

**Acceptance Scenarios**:

1. **Given** a user is on any page of the Docusaurus site, **When** they open the ChatKit widget, **Then** they can type a question into the chat input.
2. **Given** a question is typed into the ChatKit widget, **When** the user submits the query, **Then** the RAG backend processes the query against the book's content and returns an answer.

---

### User Story 3 - Browse Docusaurus Content (Priority: P3)

As a reader, I want to navigate through the book's chapters and content easily.

**Why this priority**: Essential for basic documentation site functionality, providing the foundation for the AI features.

**Independent Test**: A user can browse through all static Docusaurus pages, use the sidebar and navbar for navigation, and see the chat widget remain persistent.

**Acceptance Scenarios**:

1. **Given** a user is on the Docusaurus site, **When** they use the sidebar or navbar to navigate between chapters, **Then** the page content updates, and the ChatKit widget remains visible and active.
2. **Given** the Docusaurus site is loaded, **When** the user views a chapter, **Then** the content is displayed correctly with the specified theme.

---

### Edge Cases

- What happens if no text is selected when mouseup occurs? (FAB should not appear)
- How does the system handle very long text selections? (The selected text should be truncated or summarized appropriately before being injected into the chat context, if exceeding LLM token limits.)
- What if the RAG backend is unavailable or returns an error? (The frontend should display a user-friendly error message.)
- What if the embedding API (Google Gemini) rate limit is hit during indexing? (The Librarian Script should implement appropriate retry mechanisms with backoff.)

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: The Docusaurus site MUST use the classic preset with a custom color scheme (e.g., #2e8555).
- **FR-002**: The Docusaurus site MUST autogenerate the sidebar from the `/docs` file structure.
- **FR-003**: The Navbar MUST contain links to "Chapters", "About", and "GitHub Repo".
- **FR-004**: The Docusaurus Root component (src/theme/Root.js) MUST be swizzled to wrap the entire application.
- **FR-005**: The swizzled Root component MUST listen for the global `mouseup` event.
- **FR-006**: If `window.getSelection().toString()` is not empty, the Root component MUST render a Floating Action Button (FAB) near the mouse cursor.
- **FR-007**: Clicking the FAB MUST open the ChatKit widget.
- **FR-008**: Clicking the FAB MUST inject the selected text as a system message or context object into the ChatKit widget.
- **FR-009**: Clicking the FAB MUST pre-fill the ChatKit user input with "Explain this context: ...".
- **FR-010**: The backend MUST be a FastAPI application running on `localhost:8000`.
- **FR-011**: The backend MUST use Qdrant Cloud (Free Tier) as its database.
- **FR-012**: The backend MUST expose a POST `/api/chat` endpoint for the main RAG functionality.
- **FR-013**: The backend MUST expose a POST `/api/index` admin endpoint to trigger book indexing.
- **FR-014**: The RAG logic MUST receive a user query and an optional selected text.
- **FR-015**: The RAG logic MUST convert the query (and selected text, if provided) to a vector using Google Gemini (text-embedding-004).
- **FR-016**: The RAG logic MUST query Qdrant for the top 3 relevant book chunks.
- **FR-017**: The RAG logic MUST synthesize the final answer by sending the (Query + Selected Text + Retrieved Chunks) to the LLM.
- **FR-018**: A Python script MUST be located at `scripts/index_book.py`.
- **FR-019**: The `index_book.py` script MUST scan all `.md` files in the `/docs` folder.
- **FR-020**: The `index_book.py` script MUST chunk text by headers (##) or paragraphs (approx 500 tokens).
- **FR-021**: The `index_book.py` script MUST call the Google Gemini API for embedding with `time.sleep(1)` to respect rate limits.
- **FR-022**: The `index_book.py` script MUST upload vectors + metadata (Chapter Title, Page URL) to Qdrant.
- **FR-023**: Deployment MUST be to GitHub Pages.
- **FR-024**: A GitHub Actions workflow MUST be created at `.github/workflows/deploy.yml`.
- **FR-025**: The deploy workflow MUST build Docusaurus (`npm run build`) and deploy to the `gh-pages` branch on push to `main`.
- **FR-026**: The Docusaurus site title MUST be "Cybernetic Book Documentation"

### Key Entities *(include if feature involves data)*

- **Book Chunk**: A segment of text from the book, typically a paragraph or section, used for RAG. Key attributes include `content`, `embedding` (vector), `chapter_title`, `page_url`.
- **User Query**: The text input from the user in the ChatKit widget.
- **Selected Text**: The highlighted text by the user, used to provide context to the AI.

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Users can highlight text and receive an AI explanation within 5 seconds for 90% of requests.
- **SC-002**: The RAG backend correctly retrieves relevant book chunks for 95% of queries.
- **SC-003**: The ChatKit widget remains persistent and functional across all Docusaurus page navigations.
- **SC-004**: The Docusaurus site successfully builds and deploys to GitHub Pages on every push to `main`.
- **SC-005**: The indexing script processes all `.md` files in `/docs` and updates Qdrant without errors or exceeding API rate limits within a reasonable time (e.g., 30 minutes for a medium-sized book).
- **SC-006**: The Docusaurus site is accessible and navigable on GitHub Pages.
